{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log cleaner and combiner\n",
    "\n",
    "After the timestamps have collected here I combine that log with the baseball savant log for the game. This attaches pitch outcome with an audio clip. This area is where I'll address tesseract as well (if there big I need to run it again). A couple rounds of error correction are performed.\n",
    "\n",
    "First, I by eye remove obviously wrong tesseract pulls. Second, I fix a systematic issue that occurs which I will explain here. \n",
    "\n",
    "The last pitch of the inning is often immediately followed by commercials breaks. This does not give my program time to register that last pitch, leading to the last pitch of every halfing inning typically being missed. When that pitcher returns to the mound the next inning, this would give the program a chance to register the pitch count before the first pitch is thrown. The result is logging the last pitch count of the previous inning as having occured as the first pitch of the current inning. I pull up the savant log and remove these incorrect first pitches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# MISSING INTEGER NUMBER SEQUENCE FINDER \n",
    "def missing_elements(L, start, end):\n",
    "    if end - start <= 1: \n",
    "        if L[end] - L[start] > 1:\n",
    "            yield from range(L[start] + 1, L[end])\n",
    "        return\n",
    "\n",
    "    index = start + (end - start) // 2\n",
    "\n",
    "    # is the lower half consecutive?\n",
    "    consecutive_low =  L[index] == L[start] + (index - start)\n",
    "    if not consecutive_low:\n",
    "        yield from missing_elements(L, start, index)\n",
    "\n",
    "    # is the upper part consecutive?\n",
    "    consecutive_high =  L[index] == L[end] - (end - index)\n",
    "    if not consecutive_high:\n",
    "        yield from missing_elements(L, index, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I run the following routine to find all the duplicate and missing entries in the resulting join of the two tables. \n",
    "\n",
    "A duplicate means that something obscured the CV and had it register the same pitch count twice, and for some reason, the remove duplicate action did not remove one of them.\n",
    "\n",
    "A missing entry means that the CV missed a pitch count or I deleted it because of one of the above reasons. This happens usually because of the end of the inning or a pitcher being pulled. In both cases the broadcast cuts to commercial quickly after the last pitch is thrown. Other cases are replays that eat up most of the pitch, the broadcast will jump back to the mound just before the pitch not giving the CV time to register. \n",
    "\n",
    "A log.txt is output that gives me a list of entries to correct and the log is kept for record purposes.\n",
    "\n",
    "Be sure to run this cell only once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n=0\n",
    "\n",
    "path='E://HOU18/World series 2017/games/game 3/'\n",
    "\n",
    "file1=open(f'{path}initial_miss.txt','w')\n",
    "\n",
    "df=pd.read_csv(f'{path}pitch timelog.csv')\n",
    "df2=pd.read_csv(f'{path}game 3 savant log.csv')\n",
    "\n",
    "new_df = pd.merge(df2, df,  how='left', left_on=['pitcher','pitch_count'], right_on = ['Pitcher','Pitch Count'])\n",
    "new_df.drop(['Pitch number','Pitcher','Pitch Count'],axis=1,inplace=True)\n",
    "\n",
    "L = ['clips percentage missing\\n',\n",
    "    str(round((len(new_df['time'])-new_df['time'].count())/len(new_df['time'])*100,2))+'%\\n\\n'] \n",
    "\n",
    "file1.writelines(L)  \n",
    "\n",
    "new_df=new_df[~new_df['time'].isnull()]\n",
    "\n",
    "new_df.to_csv(f'{path}pitch outcomes and time.csv',index=False)\n",
    "\n",
    "# FIND ALL THE DUPLICATE ENTRIES\n",
    "\n",
    "L=[]\n",
    "\n",
    "x=new_df[new_df.duplicated(subset=['pitcher','pitch_count'],keep='first')]\n",
    "\n",
    "file1.write('game pitch, pitcher, and pitch count that has a duplicate in initial join\\n\\n')\n",
    "\n",
    "while n <  len(x['game_pitch'].values):\n",
    "    \n",
    "    L=str((x['game_pitch'].values[n],\n",
    "    x['pitcher'].values[n],\n",
    "    x['pitch_count'].values[n]))\n",
    "    \n",
    "    file1.writelines(L)\n",
    "    file1.write('\\n')\n",
    "    n+=1\n",
    "\n",
    "file1.write('\\n')\n",
    "\n",
    "L=[]\n",
    "    \n",
    "# FIND ALL THE MISSING ENTRIES\n",
    "file1.write('game pitch, pitcher, and pitch count of missing pitches after initial join\\n')\n",
    "file1.write('\\n')\n",
    "for m in miss:\n",
    "    L=str((df2['game_pitch'][m-1],df2['pitcher'][m-1],df2['pitch_count'][m-1]))\n",
    "    file1.writelines(L)\n",
    "    file1.write('\\n')\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the initial_miss.txt as a guide I fix the pitch timelog file by hand. Watching the video and pulling the timestamps manually. Typically this is for about 6% of the entries, better than having to do 100% by hand!\n",
    "\n",
    "I'll continously run the cell until it returns 0% clips missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='E://HOU18/World series 2017/games/game 3/'\n",
    "\n",
    "df=pd.read_csv(f'{path}pitch timelog.csv')\n",
    "df2=pd.read_csv(f'{path}game 3 savant log.csv')\n",
    "\n",
    "new_df = pd.merge(df2, df,  how='left', left_on=['pitcher','pitch_count'], right_on = ['Pitcher','Pitch Count'])\n",
    "new_df.drop(['Pitch number','Pitcher','Pitch Count'],axis=1,inplace=True)\n",
    "\n",
    "print('clips percentage missing')\n",
    "print(str(round((len(new_df['time'])-new_df['time'].count())/len(new_df['time'])*100,2))+'%')\n",
    "\n",
    "L = ['clips percentage missing\\n',\n",
    "    str(round((len(new_df['time'])-new_df['time'].count())/len(new_df['time'])*100,2))+'%\\n']  \n",
    "\n",
    "new_df=new_df[~new_df['time'].isnull()]\n",
    "\n",
    "new_df.to_csv(f'{path}pitch outcomes and time.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINING SUMMARY ROW WITH LOG\n",
    "\n",
    "This fills each row of the pitch log with a set of columns from the summary file. This is a bit redundant, with each row stating the same set of info, but seeing ths format from Tony adams, I do like that he timestamps the youtube video for each pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
